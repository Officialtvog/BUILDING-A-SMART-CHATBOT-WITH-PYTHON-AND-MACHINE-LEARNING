{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  BUILDING A SMART CHATBOT USING PYTHON AMD MACHINE LEARNING\n",
    "\n",
    "Its a view of confirmation of the building process\n",
    "well i was intending to get some words from the website of tech reyal to actualy initialize the level of smartness of my chatbot,but as time goes on..you would see somethings.\n",
    "the remaining codes to show the level of automation of my chatbot are left in me....\n",
    "\n",
    "this is just a view to let you see the possiblity of building a chatbot with python and machine learning\n",
    "\n",
    "I AM OLANIPEKUN TEMITOPE(the ML engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS A SMART CHATBOT PROGRAMME\n",
    "#pip install nltk\n",
    "#pip install newspaper3k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "\n",
    "from newspaper import Article\n",
    "import random \n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download the punkt package\n",
    "nltk.download(\"punkt\" , quiet = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(\"https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-203545521\")\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "corpus = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(\"https://www.techreyal.org/about.html\")\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "corpus = article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who We Are\n",
      "\n",
      "We are the pace setters out solely to solve problems within the Tech space. We major in Software development and Data Science as a way of preparing for the future. While we deliver top notch websites, brands and digital products, we also use state-of-the art technologies and innovations to train and build exceptional developers and data scientist\n"
     ]
    }
   ],
   "source": [
    "#print the articles text\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokeniztion\n",
    "text = corpus\n",
    "sentence_list = nltk.sent_tokenize(text) #A LIST of senetences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who We Are\\n\\nWe are the pace setters out solely to solve problems within the Tech space.', 'We major in Software development and Data Science as a way of preparing for the future.', 'While we deliver top notch websites, brands and digital products, we also use state-of-the art technologies and innovations to train and build exceptional developers and data scientist']\n"
     ]
    }
   ],
   "source": [
    "#print list of sentences\n",
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to return a random greeting rsponse to a users greeting\n",
    "def greeting_response(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    #bots greeting response\n",
    "    bot_greetings = [\"How you dey\", \"hello\",\"howdy\",\"whatsgood\",\"hihi\",\"OMO i dey O\",\"update dey\"]\n",
    "    \n",
    "    #users response\n",
    "    user_greetings = [\"hihi\",\"whatsup\",\"holla\",\"hey\",\"yo\" \"How you dey\",\"any update\"]\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in user_greetings:\n",
    "            return random.choice(bot_greetings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_sort(list_var):\n",
    "    length = len(list_var)\n",
    "    list_index = list(range(0, length))\n",
    "    x = list_var\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if x[list_index[i]] > x[list_index[j]]:\n",
    "            #Swap\n",
    "            #this is our temporary values\n",
    "                temp = list_index[i]\n",
    "                list_index[i] = list_index[j]\n",
    "                list_index[j]= temp\n",
    "            \n",
    "            return list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bots response\n",
    "def bot_response(user_input):\n",
    "    user_input = user_input.lower()\n",
    "    sentence_list.append(user_input)\n",
    "    bot_response = ''\n",
    "    cm = CountVectorizer().fit_transform(sentence_list)\n",
    "    similarity_scores = cosine_similarity(cm[-1],cm)\n",
    "    similarity_scores_list = similarity_scores.flatten()\n",
    "    index = index_sort(similarity_scores_list)\n",
    "    index = index[1:]#what index to contain only values that are not itself and {1} onwards\n",
    "    response_flag = 0\n",
    "    # we will use this to see if there is a response back to the users and also if the similarity scores found a\n",
    "    #sentence tha is similar to the text to what the users  query is\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(len(index)):\n",
    "        if similarity_scores_list[index[i]] >0.0:\n",
    "            bot_response = bot_response+' '+sentence_list[index[i]]\n",
    "            response_flag = 1\n",
    "            j = j+1\n",
    "            if j > 2:\n",
    "                break\n",
    "                \n",
    "                if response == 0:\n",
    "                    bot_response = bot_response+ ' '+ \"I apologise i dont understand .\"\n",
    "                    senetence_list.remove(user_input)\n",
    "                    return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ML temitopes chatbot:  lets talk\n",
      "hihi\n",
      "ML temitopes chatbot: OMO i dey O\n",
      "holla\n",
      "ML temitopes chatbot: update dey\n"
     ]
    }
   ],
   "source": [
    "#start the chat\n",
    "print(\" ML temitopes chatbot:  lets talk\")\n",
    "\n",
    "#create a list that will make the loop to stop\n",
    "exit_list = ['exit','see you later','bye','quit','break']\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    user_input = input()\n",
    "    if user_input.lower() in exit_list:\n",
    "        print('ML temitopes chatbot: talk to you later!')\n",
    "        break    \n",
    "    else:\n",
    "        if greeting_response(user_input) != None:\n",
    "            print(\"ML temitopes chatbot: \" +greeting_response(user_input))\n",
    "        else:\n",
    "            print(\"ML temitopes chatbot: \" +bot_response(user_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, are the coversations taken place..between me and my chatbots...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So i have been working with dialogflow and RASA NLU for some time now and i expertise in chatbot development,i have completed some bots\n",
    "\n",
    "bots,i expertise in dialogflow development as well for different platforms inlcuding,whatsapp,telegram and websites etc.\n",
    "\n",
    "but i just played around to show some stuffs with python and machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
